{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender Expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About Dataset\n",
    "##### From: [Dataset](http://www.zhuolin.umiacs.io/projectlcksvd.html)\n",
    "Bộ cơ sở dữ liệu này bao gồm 2600 ảnh, chia làm 100 lớp (mỗi lớp ứng với một người), tức mỗi người có 26 ảnh\n",
    "Mỗi bức ảnh trong AR Face thu gọn được đặt tên dưới dạng G-xxx-yy.bmp\n",
    "- G nhận một trong hai giá trị M (man) hoặc W (woman)\n",
    "- xxx là id của người, nhận gía trị từ 001 đến 126\n",
    "- yy là điều kiện chụp, nhận giá trị từ 01 đến 26<br>\n",
    "\n",
    "Desciption:\n",
    "(1) featureMat:(540x2600)\n",
    "A matrix of random features. Each column is random face feature vector\n",
    "\n",
    "(2) filenameMat 1x100 cells (cell 1x26)\n",
    "Image file names. Each cell correspond to the features from the same class in 'featureMat'. \n",
    "\n",
    "(3) labelMat:\n",
    "This is a label matrix, each column corresponds to one random face feature, where the non-zero position of each column \n",
    "indicates the class of the random face feature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model \n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import misc      \n",
    "from scipy.io import loadmat\n",
    "from sklearn import preprocessing\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'dataset/faces'\n",
    "faces_data = loadmat(path)\n",
    "featureMat = faces_data['featureMat']\n",
    "filenameMat = faces_data['filenameMat'][0]\n",
    "labelMat = faces_data['labelMat']\n",
    "\n",
    "d = 540 #dimension \n",
    "N = 2600 # the number of feature vector\n",
    "randID = np.random.permutation(np.arange(0, N))\n",
    "train_ids = randID[0:int(N/2)]\n",
    "train_size = train_ids.shape[0]\n",
    "test_ids = randID[int(N/2) + 1:]\n",
    "test_size = test_ids.shape[0]\n",
    "view_ids = np.arange(0, 26 )\n",
    "\n",
    "gender = np.char.split(filenameMat[9][0][0][0], sep='-')\n",
    "gender = np.char.split(filenameMat[6][0][0][0], sep='-')\n",
    "\n",
    "gender.tolist()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_matrix(vector_ids, d, size, featureMat, filenameMat, labelMat ):\n",
    "    X = np.empty((d,1))\n",
    "    y = np.empty((1, 1))\n",
    "    for j in vector_ids:\n",
    "        X = np.concatenate((X, featureMat[:,j].reshape(d,1)), axis = 1)\n",
    "        person = np.argwhere(labelMat[:,j] == 1)\n",
    "        gender = np.char.split(filenameMat[person[0][0]][0][0][0], sep='-').tolist()[0]\n",
    "        if (gender == 'M'):\n",
    "            y = np.concatenate((y, [[1]]), axis = 0)\n",
    "        else:\n",
    "            y = np.concatenate((y, [[0]]), axis = 0)\n",
    "    X = X[:, 1:]\n",
    "    y = y[1:, :].flatten()\n",
    "    return (X, y)\n",
    "\n",
    "\n",
    "X_train, y_train = build_data_matrix(train_ids, d, train_size, featureMat, filenameMat, labelMat)  \n",
    "X_test, y_test = build_data_matrix(test_ids, d, test_size, featureMat, filenameMat, labelMat)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression - Step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows 10\\AppData\\Local\\Temp\\ipykernel_11536\\818875205.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1 + np.exp(-s))\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(s):\n",
    "    return 1/(1 + np.exp(-s))\n",
    "\n",
    "def logistic_sigmoid_regression(X_bar, y, w_init, eta, tol = 1e-8, max_count = 1000000):\n",
    "    w = [w_init]    \n",
    "    it = 0\n",
    "    N = X_bar.shape[1]\n",
    "    d = X_bar.shape[0]\n",
    "    count = 0\n",
    "    check_w_after = 2600\n",
    "    while count < max_count:\n",
    "        # mix data for SGD \n",
    "        mix_id = np.random.permutation(N)\n",
    "        for i in mix_id:\n",
    "            xi = X_bar[:, i].reshape(d, 1)\n",
    "            yi = y[i]\n",
    "            zi = sigmoid(np.dot(w[-1].T, xi))\n",
    "            w_new = w[-1] + eta*(yi - zi)*xi\n",
    "            count += 1\n",
    "            # stopping criteria\n",
    "            if count%check_w_after == 0:                \n",
    "                if np.linalg.norm(w_new - w[-check_w_after]) < tol:\n",
    "                    return w\n",
    "            w.append(w_new)\n",
    "    return w\n",
    "\n",
    "\n",
    "eta = .05 \n",
    "X_train_bar= np.concatenate((np.ones((1, X_train.shape[1])), X_train), axis = 0)\n",
    "X_test_bar= np.concatenate((np.ones((1, X_test.shape[1])), X_test), axis = 0)\n",
    "d = X_train_bar.shape[0]\n",
    "w_init = np.random.randn(d, 1)\n",
    "w = logistic_sigmoid_regression(X_train_bar, y_train, w_init, eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.69 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows 10\\AppData\\Local\\Temp\\ipykernel_11536\\818875205.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1 + np.exp(-s))\n"
     ]
    }
   ],
   "source": [
    "w0 = w[-1]\n",
    "\n",
    "def review(w, X_bar, y, size):\n",
    "    y_pre = np.ones(size)\n",
    "    for i in range(size):\n",
    "        xi = X_bar[:, i].reshape(d, 1)\n",
    "        zi = sigmoid(np.dot(w.T, xi))\n",
    "        if (zi < 0.5):\n",
    "            y_pre[i] = 0\n",
    "    print (\"Accuracy: %.2f %%\" %(100*accuracy_score(y, y_pre)))\n",
    "\n",
    "review(w0, X_test_bar, y_test, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using  linear_model.LogisticRegression\n",
    "Chú ý: Hàm sklearn.linear_model.LogisticRegression nhận dữ liệu ở dạng vector hàng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.46 %\n"
     ]
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression(C=1e5) # just a big number \n",
    "logreg.fit(X_train.T, y_train) #Mo\n",
    "\n",
    "y_pred = logreg.predict(X_test.T)\n",
    "print (\"Accuracy: %.2f %%\" %(100*accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
